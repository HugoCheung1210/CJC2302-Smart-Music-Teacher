{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-13T10:21:45.495672Z","iopub.status.busy":"2024-04-13T10:21:45.495155Z","iopub.status.idle":"2024-04-13T10:21:50.012942Z","shell.execute_reply":"2024-04-13T10:21:50.011986Z","shell.execute_reply.started":"2024-04-13T10:21:45.495645Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","import copy\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T05:50:20.328063Z","iopub.status.busy":"2024-02-23T05:50:20.327651Z","iopub.status.idle":"2024-02-23T05:50:20.344463Z","shell.execute_reply":"2024-02-23T05:50:20.342812Z","shell.execute_reply.started":"2024-02-23T05:50:20.328032Z"},"trusted":true},"outputs":[],"source":["# Data statistic\n","def data_stat():\n","    separated_data = []\n","    labels = []\n","\n","    for dirname, _, filenames in os.walk('/kaggle/input'):\n","        for filename in filenames:\n","            if filename == \"cross-era_annotations.csv\" or filename==\"testing.csv\": continue\n","\n","            path = os.path.join(dirname, filename)\n","            data_array = []\n","            df = pd.read_csv(path, header = None)\n","            for row in df.itertuples(index = False):\n","                if pd.notna(row[0]):\n","                        label = ((row[0].split('_'))[1].split('/'))[0]\n","                        if len(data_array)!= 0:\n","                            labels.append(label)\n","                            separated_data.append(data_array)\n","                            data_array=[]\n","                        else: continue\n","                else:\n","                    data_array.append(row[1:])\n","            labels.append(label)\n","            separated_data.append(data_array)\n","\n","\n","    lengths = [len(arr) for arr in separated_data]\n","\n","    len_idx = []\n","    steps = 1000\n","    median_len = np.median(lengths)\n","    print(f\"Median of the data: {median_len}\")\n","\n","    for i in range(len(lengths)):\n","        len_idx.append((lengths[i]//steps))\n","\n","    for i in range((max(lengths)//steps)+1):\n","        occurence = len_idx.count(i)\n","        print(f\"From length of {i*steps} to {(i+1)*steps}: \"+ str(occurence))\n","        \n","    \n","    # Data preprocessing method 1 --> padding into median of data's length\n","\n","    processed_data = []\n","    for data_arr in separated_data:\n","        if len(data_arr) >= median_len:\n","            processed_data.append(data_arr[:int(median_len)])\n","        else:\n","            padded_data = np.pad(data_arr, ((0, int(median_len)-len(data_arr)), (0,0)), mode='constant', constant_values=0)\n","            processed_data.append(padded_data)\n","\n","\n","    # print(len_idx)\n","    print(len(processed_data))\n","    print(len(labels))"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T10:23:51.948676Z","iopub.status.busy":"2024-04-13T10:23:51.947792Z","iopub.status.idle":"2024-04-13T10:24:38.671750Z","shell.execute_reply":"2024-04-13T10:24:38.670945Z","shell.execute_reply.started":"2024-04-13T10:23:51.948622Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2533281546.py:13: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(path, header = None)\n"]}],"source":["# Data preprocessing method 2 --> Splitting data by self defined length\n","\n","\n","processed_data = []\n","labels = []\n","\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        if filename == \"cross-era_annotations.csv\" or filename == \"testing.csv\": continue\n","            \n","        path = os.path.join(dirname, filename)\n","        data_array = []\n","        df = pd.read_csv(path, header = None)\n","        for row in df.itertuples(index = False):\n","                    if pd.notna(row[0]):\n","                        label = ((row[0].split('_'))[1].split('/'))[0]\n","                        data_array=[]\n","\n","                    elif len(data_array) == 100:\n","                        processed_data.append(data_array)\n","                        labels.append(label)\n","                        data_array = []\n","                    else: \n","                        data_array.append(row[1:])\n","                        \n","                        "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-13T10:24:40.675077Z","iopub.status.busy":"2024-04-13T10:24:40.674364Z","iopub.status.idle":"2024-04-13T10:24:40.679992Z","shell.execute_reply":"2024-04-13T10:24:40.678982Z","shell.execute_reply.started":"2024-04-13T10:24:40.675034Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), (0.8, 0.0995842, 0.237683, 0.000462333, 1.97254, 0.900086, 0.0, 0.310047, 0.0274636, 0.0880705, 3.72477, 0.352272, 0.0892524), (0.9, 0.0517734, 0.208381, 0.00231392, 0.627596, 0.758975, 0.383647, 0.00305628, 0.0104645, 0.0, 3.56806, 0.775066, 0.189792), (1.0, 0.000418317, 0.221696, 0.0552435, 0.402648, 1.58262, 0.11958, 0.00904782, 0.0418296, 0.283298, 4.32629, 0.230467, 0.000321715), (1.1, 0.000515347, 0.241635, 0.0, 0.134457, 1.90284, 0.0238204, 0.0444569, 0.0108937, 0.0204232, 4.28055, 0.141912, 0.000446513), (1.2, 0.000585957, 0.602695, 2.12473e-05, 0.00478037, 2.2024, 0.0, 0.0, 0.0291959, 0.151034, 3.97974, 0.162688, 0.0895368), (1.3, 0.0, 0.0, 1.99182, 0.103336, 0.683404, 0.0062247, 0.0918171, 0.0190031, 0.468424, 3.72578, 0.0555782, 0.0), (1.4, 0.0, 0.349388, 2.36878, 0.0207316, 0.21694, 0.0140306, 0.0571799, 0.0, 0.11743, 3.69447, 0.0816273, 0.0), (1.5, 0.0, 2.67928, 0.131609, 0.0190754, 0.247815, 0.100959, 0.20358, 0.0314832, 0.289998, 3.26882, 0.136634, 0.0), (1.6, 0.0224631, 1.18485, 0.307782, 0.074067, 1.07952, 0.0306749, 0.301606, 0.00856847, 0.523716, 3.83321, 0.0, 1.22021), (1.7, 0.0180261, 1.37514, 1.27044, 0.0131641, 0.588679, 0.0, 0.245046, 0.0198143, 0.057428, 3.94541, 0.111401, 0.859008), (1.8, 0.000712398, 0.651665, 0.16361, 0.0, 1.72589, 0.0, 0.0, 0.00427198, 0.575547, 3.48066, 0.144414, 0.576466), (1.9, 0.0, 0.982412, 0.0, 0.0, 2.61183, 0.0372962, 0.0330978, 0.0361616, 0.254491, 3.6293, 0.207348, 0.361099), (2.0, 0.0632839, 0.902863, 0.00195701, 0.01557, 2.21241, 0.0421251, 0.210332, 0.0, 0.0704811, 3.91373, 0.0, 0.340436), (2.1, 0.0379957, 2.29335, 0.0, 0.141637, 2.4623, 0.0720098, 0.0147093, 0.0, 0.173201, 3.09923, 0.093933, 0.218754), (2.2, 0.0776879, 0.926403, 0.0, 0.0850535, 2.22493, 0.0357909, 0.0394446, 0.102526, 0.346027, 4.01011, 0.0441123, 0.000251366), (2.3, 0.00403255, 0.870905, 6.48691e-05, 0.155002, 2.06772, 0.0, 0.00850155, 0.124617, 0.311893, 4.24283, 0.0358766, 0.000199269), (2.4, 0.000451454, 1.16862, 0.0, 0.115566, 2.21526, 0.0336642, 0.0298184, 0.11168, 0.122793, 3.8535, 0.246768, 0.0626807), (2.5, 0.377357, 0.820222, 0.00151358, 0.416228, 1.6238, 0.0996352, 0.0207792, 0.258422, 0.0357055, 3.99141, 0.112754, 0.106448), (2.6, 0.000505065, 0.897293, 0.0403988, 0.00109797, 2.30118, 0.00113761, 0.0140512, 0.0547708, 0.0852024, 3.02785, 0.194551, 0.530312), (2.7, 0.000467583, 1.42199, 0.0118611, 0.799751, 1.34532, 0.0468268, 0.0542718, 0.0263905, 0.413125, 3.65424, 0.0, 0.731376), (2.8, 0.0, 2.96248, 0.00234277, 0.00218783, 1.56689, 0.0395095, 0.0310988, 0.0506206, 0.457076, 3.56043, 0.0310218, 0.000632204), (2.9, 0.0, 2.28067, 0.00177706, 0.011126, 1.46158, 0.0, 0.00160831, 0.0705539, 0.121046, 4.48557, 0.028125, 0.000481556), (3.0, 0.0, 1.9584, 0.00292667, 0.0144775, 1.6627, 0.0283349, 0.0648042, 0.012834, 0.394132, 4.0755, 0.0, 0.000182969), (3.1, 0.143423, 1.78321, 0.00351763, 0.0192952, 1.96767, 0.0, 0.0, 0.017013, 0.0276355, 4.05895, 0.0, 0.104978), (3.2, 0.00066351, 2.16048, 0.855128, 0.00045366, 0.784877, 0.0, 0.0274927, 0.0213518, 0.305062, 3.83386, 0.0, 0.126569), (3.3, 0.104902, 0.65934, 2.82139, 0.0153938, 0.100476, 0.0, 0.0903116, 0.0321743, 0.0728511, 3.64452, 0.0, 0.0), (3.4, 0.000304146, 3.02206, 0.654525, 0.00481379, 0.0, 0.117303, 0.00866499, 0.0, 0.234169, 3.46026, 0.15752, 0.000186392), (3.5, 0.0, 2.17235, 0.410649, 0.0103919, 0.609893, 0.0880656, 0.518238, 0.00784011, 0.393168, 3.91287, 0.10294, 0.388301), (3.6, 0.101518, 1.18859, 0.58848, 0.0198974, 1.24791, 0.168757, 0.363864, 0.00262457, 0.525181, 3.08453, 0.039405, 1.77195), (3.7, 0.0432508, 1.71965, 0.907248, 0.0162017, 0.973757, 0.0411914, 0.150709, 1.67844, 0.75911, 3.07389, 0.0, 0.489041), (3.8, 0.0109381, 1.31071, 0.149059, 0.0147191, 1.37144, 0.0, 0.0, 2.33116, 0.114846, 2.50999, 0.0348719, 0.141561), (3.9, 0.0698046, 1.80278, 0.236876, 0.0146881, 0.513473, 0.0, 0.0, 2.34519, 0.218502, 2.45575, 0.130669, 0.103421), (4.0, 0.0473231, 0.230652, 0.0932901, 0.0, 2.01381, 0.0399897, 0.0523595, 1.74989, 0.62828, 2.42621, 0.0, 0.501313), (4.1, 0.0, 0.441555, 0.0644339, 0.0139913, 2.34396, 0.0552775, 0.0, 2.26785, 0.0391669, 2.46253, 0.129825, 0.473509), (4.2, 3.97373e-06, 2.20123, 0.00451068, 0.0, 1.41235, 0.11332, 0.0451807, 2.04937, 0.685147, 2.11326, 0.052051, 0.20268), (4.3, 0.000505198, 2.63766, 0.0, 0.0, 0.899156, 0.0919568, 0.0, 1.51748, 0.377626, 2.50365, 0.110662, 0.023682), (4.4, 0.0359204, 2.44277, 0.00245363, 0.0075675, 2.09393, 0.083113, 0.039303, 1.79715, 0.0211249, 1.87738, 0.0238137, 0.05833), (4.5, 0.000559078, 1.29612, 0.53657, 0.0474763, 1.19755, 0.0279133, 0.042109, 3.27787, 0.201718, 2.03191, 0.0104749, 0.224153), (4.6, 0.000116731, 0.642483, 0.689273, 0.0146836, 1.34004, 0.0350468, 0.00362058, 2.42878, 0.394254, 2.47586, 0.0, 0.0220607), (4.7, 0.209592, 1.57761, 0.0, 0.0113715, 1.74467, 0.0, 0.00297616, 0.652777, 0.156442, 4.20664, 0.0745726, 0.0926518), (4.8, 0.000550919, 2.26728, 0.0, 0.0, 1.89333, 0.0, 0.00108535, 0.0565404, 0.0, 4.15372, 0.223051, 0.0), (4.9, 0.0147453, 1.80766, 0.0, 0.0, 1.66238, 0.0256224, 0.0150406, 0.0125381, 0.142276, 4.217, 0.00274449, 0.139038), (5.0, 0.109059, 1.26504, 0.00316245, 0.0173353, 1.34253, 0.0, 0.00672294, 0.00972958, 0.0, 4.56159, 0.0999492, 0.0), (5.1, 0.099203, 0.655943, 1.39099, 0.0518049, 0.797129, 0.0, 0.0713555, 0.00666928, 0.0324704, 3.7808, 0.137033, 0.0), (5.2, 0.298787, 0.580282, 2.63272, 0.0130039, 0.000252488, 0.0, 0.0828718, 0.372066, 0.116226, 3.60359, 0.0, 0.0506573), (5.3, 0.0, 2.75705, 0.955964, 0.0161388, 0.366207, 0.0972559, 0.0461699, 0.0326675, 0.391502, 3.31105, 0.114873, 0.000753857), (5.4, 0.000535818, 1.90771, 0.539715, 0.0492187, 0.380449, 0.0, 0.718574, 0.0024338, 0.414195, 2.29455, 0.104876, 1.21321), (5.5, 0.430471, 1.88508, 0.00249, 0.122006, 0.328084, 0.0, 0.294401, 0.0508815, 0.091384, 3.57382, 0.0, 1.4993), (5.6, 0.310735, 1.82698, 0.164131, 0.0166746, 0.400738, 0.0690364, 0.587727, 2.4748e-05, 0.353151, 3.31665, 0.620366, 0.395108), (5.7, 0.0127844, 2.023, 0.0342361, 0.0, 0.643742, 0.888036, 0.555355, 0.455525, 0.193091, 1.26223, 2.20204, 0.0), (5.8, 0.351454, 2.25382, 0.0031243, 0.015179, 1.5391, 0.0579658, 0.287548, 0.521432, 0.116267, 1.21932, 1.8996, 0.0), (5.9, 0.221714, 2.10217, 0.0017037, 0.0144287, 2.04106, 0.0477516, 0.185317, 1.95154, 0.415927, 0.603182, 1.59545, 0.0241385), (6.0, 0.187789, 2.0314, 0.0644782, 0.0149976, 1.87168, 0.177088, 0.197918, 2.18681, 0.311104, 0.92535, 1.63804, 0.304705), (6.1, 1.45518, 1.33448, 0.304057, 0.073107, 1.05878, 1.7616, 0.389507, 0.605386, 0.0417126, 2.41319, 0.714268, 0.0), (6.2, 1.25454, 0.0275569, 1.39379, 0.0184252, 0.395447, 3.00829, 0.0389345, 0.653909, 0.0299579, 2.25788, 0.107487, 0.0), (6.3, 0.644709, 0.0, 2.41262, 0.0182733, 0.275363, 2.26205, 0.0640233, 0.0923356, 0.0, 2.03242, 0.0, 0.0), (6.4, 1.15203, 0.0302007, 1.84085, 0.00318784, 0.331145, 2.58321, 0.0856458, 0.782482, 0.0, 1.64915, 0.0985314, 0.109084), (6.5, 1.07431, 0.0, 2.39279, 0.0105321, 0.35629, 2.25092, 0.0975969, 0.612024, 0.0, 1.75687, 0.0028235, 0.0), (6.6, 0.384195, 0.00216593, 2.5514, 0.0648971, 1.19495, 1.1249, 0.0505597, 0.0, 0.127065, 1.65863, 0.859103, 1.08582), (6.7, 0.667062, 0.000597504, 2.50653, 0.125423, 1.87226, 0.652657, 0.0656252, 0.0514375, 0.20552, 1.31001, 0.0, 0.668183), (6.8, 0.0964539, 0.0, 2.56399, 0.288055, 1.41695, 1.03657, 0.134225, 0.0805479, 0.00257742, 1.57573, 0.0, 0.441743), (6.9, 0.51664, 0.000584223, 2.18928, 0.133901, 2.39973, 0.233495, 0.0294414, 1.3921, 0.0, 0.0, 0.864454, 1.80466), (7.0, 0.435019, 0.065377, 2.28312, 0.0184093, 2.21432, 1.06342, 0.0256163, 1.73117, 0.0168602, 0.195675, 0.0, 1.95551), (7.1, 0.195044, 1.28192, 0.825101, 0.200747, 0.456493, 1.80323, 0.0543209, 0.198688, 1.21423, 2.79505, 0.0, 0.7475), (7.2, 0.0, 1.86054, 0.525808, 0.549468, 0.566662, 1.3899, 0.0, 0.496405, 0.778505, 2.66836, 0.141202, 0.0387988), (7.3, 0.128943, 2.18757, 0.0698577, 0.0668286, 1.16355, 0.72701, 0.0, 0.332707, 0.496202, 3.46407, 0.0, 2.40196e-05), (7.4, 0.211163, 1.42156, 0.255946, 0.0173253, 2.27044, 0.171079, 0.0, 0.0602345, 0.628944, 3.26272, 0.0, 0.13628), (7.5, 0.168011, 2.39225, 0.564971, 0.0226149, 1.85037, 0.134259, 0.0160445, 0.113669, 0.347135, 3.19238, 0.0, 0.218724), (7.6, 0.372593, 0.722267, 3.32243, 0.0780746, 0.0189447, 1.55229, 0.155076, 0.136537, 0.273953, 2.1344, 0.0, 0.0), (7.7, 0.0836169, 1.15403, 2.61928, 0.151598, 1.432, 1.56906, 0.00839559, 0.0682096, 0.0855214, 2.47162, 0.0, 0.0), (7.8, 0.331786, 0.326385, 2.91925, 0.0157788, 1.70408, 1.52932, 0.0622756, 0.0345441, 0.0999035, 2.89452, 0.0, 0.0077881), (7.9, 1.01364, 0.192214, 1.5781, 0.318965, 1.53864, 1.84009, 0.14275, 0.0505327, 0.0547834, 2.73351, 0.0, 0.0), (8.0, 0.894365, 0.320126, 2.15364, 0.0276276, 0.363917, 2.27862, 0.19088, 0.0924252, 0.746674, 2.31966, 0.465507, 0.0649235), (8.1, 0.601581, 0.00184709, 2.71682, 0.0205428, 0.769531, 2.01314, 0.0181001, 0.0, 0.560689, 2.60078, 0.0, 0.0664432), (8.2, 0.588947, 0.0933912, 3.31976, 0.109335, 0.848282, 1.56134, 0.0952929, 0.0841206, 0.119729, 2.30058, 0.000259656, 0.0), (8.3, 0.439841, 0.000482491, 2.97696, 0.172351, 0.641247, 1.06955, 0.198451, 0.117116, 0.0238021, 2.98702, 0.0, 0.0), (8.4, 0.000569319, 0.0227651, 2.97527, 0.293424, 1.52619, 1.12322, 0.0393021, 0.330165, 0.0, 2.3003, 0.0284478, 0.0), (8.5, 0.0141598, 0.00158583, 2.85132, 0.207846, 1.71184, 0.746151, 0.0408764, 0.0, 0.0, 2.7794, 0.29284, 0.0), (8.6, 0.346807, 0.372508, 2.32287, 0.0277394, 1.3002, 0.80523, 0.0, 0.0, 0.246315, 2.7427, 0.0, 0.452623), (8.7, 0.240657, 0.00238709, 2.04433, 0.119764, 1.32103, 0.451342, 0.0, 0.0, 0.646449, 2.69464, 0.0, 0.047119), (8.8, 0.000417932, 0.0111774, 3.12358, 0.44251, 0.134553, 1.43029, 0.0179859, 0.0, 0.409442, 2.6182, 0.0, 0.0435586), (8.9, 0.00043741, 0.0268302, 3.08072, 0.146663, 0.570564, 1.19175, 0.0529595, 0.0, 0.143695, 2.07813, 0.509089, 0.0), (9.0, 1.05038, 0.266073, 2.59661, 0.198009, 0.379763, 1.2018, 0.0314544, 0.0802035, 0.464541, 1.60309, 0.247448, 0.322794), (9.1, 0.962488, 1.41829, 1.36398, 0.0554788, 0.1242, 1.00918, 0.186251, 0.0598279, 0.182895, 1.28988, 0.19905, 0.0), (9.2, 0.643197, 1.21216, 1.72209, 0.0149405, 0.183081, 0.546112, 0.172338, 0.0326907, 0.0702412, 0.293904, 1.49944, 0.0767327), (9.3, 0.00187209, 1.30541, 1.10717, 0.164318, 0.854503, 1.12966, 0.0769998, 0.0617268, 0.103418, 2.42083, 0.639569, 0.195781), (9.4, 0.974077, 0.737293, 1.36383, 0.805889, 0.722402, 0.979488, 0.0467925, 1.35435, 0.0, 1.69085, 0.667673, 0.0208993), (9.5, 0.830273, 0.0745944, 2.05763, 0.0157229, 0.0581435, 2.27679, 0.0357713, 1.25115, 0.0, 1.39279, 0.405802, 0.165641), (9.6, 0.147045, 0.155072, 3.52533, 0.0, 0.0269302, 2.67556, 0.0409453, 0.188669, 0.0478809, 1.76829, 0.248262, 0.000714538), (9.7, 0.048729, 0.00187164, 3.42662, 0.00350571, 0.665532, 1.3632, 0.233018, 0.134261, 0.451219, 1.92921, 0.0979376, 0.392692), (9.8, 0.796557, 0.000534428, 1.59634, 0.219459, 0.689796, 3.46958, 0.109877, 0.219839, 0.731322, 0.504739, 0.0248069, 0.0), (9.9, 0.876747, 0.184417, 0.60041, 0.0951585, 2.86526, 2.26286, 0.158973, 0.0182304, 0.100684, 0.0228272, 0.147378, 1.83534), (10.0, 1.31963, 0.586152, 1.7763, 0.0243585, 1.77009, 1.5149, 0.551436, 0.115027, 0.382974, 0.510568, 1.80592e-05, 0.273271)]\n"]}],"source":["print(processed_data[1])\n","\n","# transposed_data = np.roll(processed_data[0][5:10], 1,axis = 0)\n","# print(transposed_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:03:03.630501Z","iopub.status.busy":"2024-02-23T06:03:03.630094Z","iopub.status.idle":"2024-02-23T06:03:03.671212Z","shell.execute_reply":"2024-02-23T06:03:03.669808Z","shell.execute_reply.started":"2024-02-23T06:03:03.630462Z"},"trusted":true},"outputs":[],"source":["label_map = {'romantic': 0, 'baroque': 1, 'modern': 2, 'addon': 3, 'classical': 4}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if torch.cuda.is_available():\n","    print(\"Using Cuda\")\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        # Get audio sequence\n","        input_data = np.array(self.data[idx])\n","        \n","#         input_data = input_data.reshape(-1, input_data.shape[-1])\n","        input_data = torch.tensor(input_data, dtype=torch.float32)\n","\n","        label = [label_map[label_name] for label_name in self.labels]\n","        return input_data, torch.tensor(label[idx])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","        \n","\n","dataset = Dataset(data = processed_data, labels = labels)\n","train_length = int(len(dataset)*0.9)\n","test_length = int(len(dataset))-train_length\n","\n","train_dataset,test_dataset=torch.utils.data.random_split(dataset,[train_length,test_length])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:03.118871Z","iopub.status.busy":"2024-02-23T06:04:03.118471Z","iopub.status.idle":"2024-02-23T06:04:03.137755Z","shell.execute_reply":"2024-02-23T06:04:03.136755Z","shell.execute_reply.started":"2024-02-23T06:04:03.118841Z"},"trusted":true},"outputs":[],"source":["\n","class BiLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(BiLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  \n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  \n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n","\n","        out, _ = self.lstm(x, (h0, c0))  \n","        out = self.fc(out[:, -1, :])  \n","        prob = F.softmax(out, dim=1)  \n","\n","        return out,prob\n","\n","    \n","class CNN_BiLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(CNN_BiLSTM, self).__init__()\n","        # CNN layers\n","        self.cnn = nn.Sequential(\n","            nn.Conv1d(input_size, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2, stride=2),\n","            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2, stride=2),\n","        )\n","        \n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(16, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  \n","\n","    def forward(self, x):\n","        x = x.permute(0, 2, 1)  # Reshape for CNN (batch_size, input_size, sequence_length)\n","        batch_size, input_size, sequence_length = x.size()\n","        x = x.view(-1, input_size, sequence_length)  # Reshape to apply CNN independently to each feature sequence\n","        cnn_output = self.cnn(x)\n","        cnn_output = cnn_output.view(batch_size, sequence_length, -1)  # Reshape back to original size        \n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  \n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n","\n","        out, _ = self.lstm(cnn_output, (h0, c0))  \n","        out = self.fc(out[:, -1, :])  \n","        prob = F.softmax(out, dim=1)  \n","\n","        return out,prob"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:08.709980Z","iopub.status.busy":"2024-02-23T06:04:08.709559Z","iopub.status.idle":"2024-02-23T06:04:08.719595Z","shell.execute_reply":"2024-02-23T06:04:08.718778Z","shell.execute_reply.started":"2024-02-23T06:04:08.709947Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion,optimizer,train_loader, num_epochs=10):\n","    model.train() \n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        # Forward\n","        outputs, probs = model(inputs)\n","        _, preds = torch.max(probs, 1)\n","        loss = criterion(outputs, labels)\n","        running_loss += loss.item() * inputs.size(0)\n","        # Backward\n","        loss.backward()\n","        optimizer.step()\n","        total += labels.size(0)\n","        correct += (preds == labels).sum().item()           \n","\n","    epoch_acc = correct / total\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","    print()      \n","    return model, optimizer, epoch_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:10.668770Z","iopub.status.busy":"2024-02-23T06:04:10.668347Z","iopub.status.idle":"2024-02-23T06:04:10.679395Z","shell.execute_reply":"2024-02-23T06:04:10.678393Z","shell.execute_reply.started":"2024-02-23T06:04:10.668735Z"},"trusted":true},"outputs":[],"source":["def val_model(model, criterion, optimizer, test_loader, num_epochs=10):\n","    model.eval() \n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    y_pred=[]\n","    y_true=[]\n","    for inputs, labels in test_loader:   \n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        # Forward\n","        outputs,probs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, preds = torch.max(probs, 1)\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        total += labels.size(0)\n","        correct += (preds == labels).sum().item()\n","\n","        pred = outputs.data.argmax(1).cpu().numpy()\n","        y_pred.extend(pred)\n","        true = labels.data.cpu().numpy()\n","        y_true.extend(true)\n","\n","    epoch_acc = correct / total\n","    epoch_loss = running_loss / len(test_loader.dataset)\n","    print(f'Testing Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","    print()      \n","    return model, epoch_loss, epoch_acc, y_pred, y_true"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:14.460172Z","iopub.status.busy":"2024-02-23T06:04:14.459760Z","iopub.status.idle":"2024-02-23T06:04:14.468420Z","shell.execute_reply":"2024-02-23T06:04:14.466925Z","shell.execute_reply.started":"2024-02-23T06:04:14.460140Z"},"trusted":true},"outputs":[],"source":["class EarlyStopper:\n","    def __init__(self, patience=1, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.min_validation_loss = float('inf')\n","\n","    def early_stop(self, validation_loss):\n","        if validation_loss < self.min_validation_loss:\n","            self.min_validation_loss = validation_loss\n","            self.counter = 0\n","        elif validation_loss > (self.min_validation_loss + self.min_delta):\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:16.150855Z","iopub.status.busy":"2024-02-23T06:04:16.150427Z","iopub.status.idle":"2024-02-23T06:04:16.161833Z","shell.execute_reply":"2024-02-23T06:04:16.160798Z","shell.execute_reply.started":"2024-02-23T06:04:16.150822Z"},"trusted":true},"outputs":[],"source":["def training_loop(model, criterion, optimizer, epochs, train_dataloader, test_dataloader):\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_acc = 0.0\n","  # set objects for storing metrics\n","  train_loss = []\n","  val_loss = []\n","  y_trues=[]\n","  y_preds=[]\n","  # Train model\n","  early_stopper = EarlyStopper(patience=10, min_delta=0.1)\n","\n","  for epoch in range(0, epochs):\n","    print(f'Epoch: {epoch+1}\\t')\n","    # training\n","    model, optimizer, t_loss = train_model(model, criterion, optimizer, train_dataloader,num_epochs=epochs)\n","    train_loss.append(train_loss)\n","\n","    # # validation\n","    with torch.no_grad():\n","      model, v_loss, acc, y_pred, y_true = val_model(model, criterion, optimizer, test_dataloader,num_epochs=epochs)\n","    \n","      val_loss.append(v_loss)\n","      y_trues.extend(y_true)\n","      y_preds.extend(y_pred)\n","    if early_stopper.early_stop(v_loss):\n","        print(\"Early Stopping...\")\n","        break\n","    if acc > best_acc:\n","      best_acc = acc\n","      best_model_wts = copy.deepcopy(model.state_dict())\n","\n","  print(f'Best val Acc: {best_acc:4f}')\n","  torch.save(best_model_wts, \"./trained.pt\")\n","\n","  model.load_state_dict(best_model_wts)\n","\n","  return train_loss,val_loss, y_trues, y_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:18.869719Z","iopub.status.busy":"2024-02-23T06:04:18.868582Z","iopub.status.idle":"2024-02-23T06:04:19.153103Z","shell.execute_reply":"2024-02-23T06:04:19.151797Z","shell.execute_reply.started":"2024-02-23T06:04:18.869636Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()\n","import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T06:04:20.373638Z","iopub.status.busy":"2024-02-23T06:04:20.373203Z","iopub.status.idle":"2024-02-23T06:06:23.545477Z","shell.execute_reply":"2024-02-23T06:06:23.543967Z","shell.execute_reply.started":"2024-02-23T06:04:20.373602Z"},"trusted":true},"outputs":[],"source":["if __name__ == '__main__': \n","\n","  model = CNN_BiLSTM(input_size=13,hidden_size=16,num_layers=2,num_classes=5).to(device)\n","  optimizer_SGD = torch.optim.SGD(model.parameters(), lr=0.05, momentum = 0.9)\n","  optimizer_adam = torch.optim.Adam(model.parameters(), lr=0.001)\n","  criterion = nn.CrossEntropyLoss()\n","  train_loss,val_loss, y_trues, y_preds = training_loop(model, criterion, optimizer_adam,750, train_loader, test_loader) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T15:58:43.625255Z","iopub.status.busy":"2024-02-20T15:58:43.624439Z","iopub.status.idle":"2024-02-20T15:58:43.807728Z","shell.execute_reply":"2024-02-20T15:58:43.806867Z","shell.execute_reply.started":"2024-02-20T15:58:43.625225Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n"," \n","plt.title(\"Validation loss of model\")\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"Loss\")\n","plt.plot(val_loss, label='Validation Loss')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4412114,"sourceId":7669678,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
